# 讲课---内存  

---




[TOC]

# 存储器层次结构

## 冯诺依曼结构
![冯诺依曼结构.jpg-23.2kB](http://static.zybuluo.com/yaowen369/3fogjrhuxfskrh69yrh1p7we/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E7%BB%93%E6%9E%84.jpg)
图1：冯诺依曼结构

数学家冯诺依曼提出的 体系结构包含以下几个要点：

> + 把程序本身当作数据来对待，程序和该程序处理的数据用同样的方式储存。
> + 计算机的数制采用二进制。
> + 计算机应该按照程序顺序执行。

我们根据这张图进行思考就可以得到一个结论，所谓计算机处理任务，就是根据输入内容，数据/程序从存储器送往CPU进行处理，然后再将结果输出。

我们思考一下，这个存储器应该具备什么样的特点。

+ 1.：**稳定，掉电不丢失数据：**
+ 2.：**存储容量大**
+ 3.：**读写速度快**
+ 4.**价格便宜**
+ 5.**体积小：**

先说结论，**完全满足我们理想条件的存储器目前还没发明出来呢**。

最常见的存储设备：**磁盘**。足够稳定；有电没电都正常存储；容量也较大；价格也可以接受，所以磁盘是我们最常见的存储设备。

计算机运行就是这样一个过程：将数据从磁盘送往CPU，供CPU进行计算，并将结果输出。

CPU的作用就是去执行指令.并且尽可能的以它的极限最高速度去执行指令，就是伴随着时钟周期滴滴答答的节奏，CPU踏着拍子来执行指令。

CPU采取了各种措施来加快执行过程(也可以理解为加快它的计算速度)。比如有以下几种常见的措施：

> + **流水线(pipeline)技术**
> + **超线程(Hyper-Threading)技术**
> + **乱序执行**: 

CPU平均执行一条指令只需要一个周期。i7 7700K主频达到了 4.2G。这也就意味着，每个core每秒钟大约可以执行4.2亿条指令。那四个core呢？

##### **CPU每秒钟可以执行几亿（甚至十几亿）条指令**

![机械硬盘结构.jpg-90.4kB](http://static.zybuluo.com/yaowen369/qb1nhqgk1kqwbemlip2akjll/%E6%9C%BA%E6%A2%B0%E7%A1%AC%E7%9B%98%E7%BB%93%E6%9E%84.jpg)

图2：机械硬盘结构

#####  **我们的目标就是执行任务时让CPU全负荷的运行，争取对于每一个时钟周期，CPU都不会闲置浪费。**

计算机体系的主要矛盾，**CPU太快了，而磁盘太慢了。所以它俩是不能够直接通信的**。

解决方案：加过度。内存条。

内存的读写速度比磁盘快几十万倍左右。所以它可以和CPU直接通信了。

这里有张图，我们来看一下磁盘/内存,与CPU速度之间逐渐增大的差距(主要是CPU技术发展太迅猛了)。

![磁盘DRAM和cpu速度之间逐渐增大的差距.png-122.1kB](http://static.zybuluo.com/yaowen369/rlrofelzhskff53mrhm0ud8v/%E7%A3%81%E7%9B%98DRAM%E5%92%8Ccpu%E9%80%9F%E5%BA%A6%E4%B9%8B%E9%97%B4%E9%80%90%E6%B8%90%E5%A2%9E%E5%A4%A7%E7%9A%84%E5%B7%AE%E8%B7%9D.png)

图三：磁盘DRAM和cpu速度之间逐渐增大的差距

所以现在程序执行过程是这样的。CPU执行任务时，只与内存通信，它从内存获取指令/数据或写回数据。内存再与磁盘通信，内存从磁盘读取数据/指令，或者内存将数据写回磁盘。


## 存储器层次结构

intel i7的存储器层次结构是这样的。

![一个存储器层次结构的示例.jpg-111.3kB](http://static.zybuluo.com/yaowen369/nuqqmsxxh7pxnfisubmzg8qq/%E4%B8%80%E4%B8%AA%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E7%9A%84%E7%A4%BA%E4%BE%8B.jpg)

图4：一个存储器层次结构的示例

那么理解了主存为什么是必要的，自然也就理解了L3，L2，L1等各级缓存存在的意义。

**这是一种缓存思想。**

一般情况下，L5磁盘与L4主存速度相差几十万倍， 而L3-L0之间，它们每级缓存的速度差异大概是10倍。

明白一点。CPU执行速度实在太快了，一秒钟执行几亿/十几亿条指令，CPU干活干脆利落，那么存储器就要想方设法的用最快的速度把指令/数据 送给CPU去运行。否则CPU干活再快，又有什么意义呢。

## RAM，ROM，总线等

存储器分为两类：
1. **易失性(volatile)存储器**:包括内存，SRAM,DRAM等，特点是读写速度很快，掉电了数据会丢失，价格贵，并且存储容量较小。
2. **非易失性(nonvolatile)存储器**：包括磁盘，Flash，光盘，机械硬盘，SSD等，与易失性存储器相比，它们读写速度很慢，但是掉电不丢失数据，存储容量比较大，价格也便宜。

+ **RAM(Random-Access Memory)**:随机访问存储器。易失性存储器。也可以访问两类：**SRAM(静态的)和DRAM(动态的)**,并且SRAM的读写速度比DRAM更快，价格也更贵。在上图中也可以看到, SRAM做L1-L3级缓存，而DRAM做L4级的主存。
+ **ROM(read-only memory)**：只读存储器，非易失性存储器。这个名字容易让人产生误解，它既可以读，也可以写，称之为read-only只是历史原因。
+ 
ROM相比于RAM，容量更大，价格便宜，读写速度则比较慢。 

+ **闪存(Flash memory)**：非易失性存储器。SSD，SD卡都属于Flash技术，如果从概念上来讲，他们都属于ROM，这类存储器经常用在手机，相机等设备上。而机械硬盘常用在个人计算机，服务器上。

就是怎么把硬盘，内存条之类的连接起来进行通信呢，这就是 总线(Bus)了。

![一个典型系统的硬件组成.jpg-91.1kB]( http://static.zybuluo.com/yaowen369/haeo9qrhslmn280ayp18v0wb/%E4%B8%80%E4%B8%AA%E5%85%B8%E5%9E%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A1%AC%E4%BB%B6%E7%BB%84%E6%88%90.jpg)

图6：一个典型系统的硬件组成

上图存在三条总线，IO总线，存储器总线(通常称为内存总线)，系统总线。在主板上，就是那一排排的32/64根并行的导线。这些导线用来连接CPU，内存，硬盘，以其他外围设备。CPU与存储器，输入输出设备等通信，都是通过总线。不同总线的速度也有差异。

## 不管中间怎么加缓存，数据从硬盘到内存的速度就是那么慢，那么这些缓存意义何在？

我们来看看，CPU如何读取磁盘中的一个数据。

![读一个磁盘扇区-1.png-27.6kB](http://static.zybuluo.com/yaowen369/fb5u30z7wb0uvlh493pq23mx/%E8%AF%BB%E4%B8%80%E4%B8%AA%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA-1.png)


![读一个磁盘扇区-2.png-138.1kB](http://static.zybuluo.com/yaowen369/wg1kuwuowflv7xnj9o8sqg7x/%E8%AF%BB%E4%B8%80%E4%B8%AA%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA-2.png)

图7：读一个磁盘扇区

注意每张图中的黑线。步骤分三部：
> 1. CPU 将相关的命令和地址，通过系统总线和IO总线传递给磁盘，发起一个磁盘读。
> 2. 磁盘控制器将相关的地址解析，并通过IO总线与内存总线将数据传给内存。
> 3. 第2步完成之后，磁盘控制器向CPU发送一个中断信号。这时CPU就知道了，数据已经发送到内存了。

##### **大量循环问题**

**在执行一个程序时，启动阶段比较慢，因为需要从磁盘读取数据。(而CPU在这个阶段也没闲置浪费，它会进行线程切换执行其他任务)。 但是数据被送往内存之后，它执行起来就会快多了，并且伴随着执行过程，还可能越来越快，因为这些数据，有可能被一级一级的向上送，从L4，送到L3，再送到L2，L1**


# 局部性原理(Principle of locality)
locality对于硬件和软件系统的设计和性能都有着重要的影响。对于我们理解存储器的层次结构也必不可缺。

**程序倾向于引用临近于与其他最近引用过的数据项的数据项。或者最近引用过的数据项本身。**这种倾向性，我们称之为局部性原理。它通常有以下两种形式：

> + 时间局部性(temporal locality):被引用过一次的存储器位置的内容在未来会被多次引用。

> + 空间局部性(spatial locality):如果一个存储器位置的内容被引用，那么它附近的位置也很大概率会被引用。

局部性好的程序
```c
int sum1(int array[N])
{
    int i, sum = 0;
    for(i = 0; i < N; i++)
        sum += array[i];
    return sum;
}
```



```c
int sum2(int array[M][N])
{
    int i, j, sum = 0;
    for(i = 0; i < M; i++){
        for(j = 0; j < N; j++)
            sum += array[j][i];
    }   
    return sum;
}
```

这是一个空间局部性很差的程序。
假设这个数组是`array[3][4]`,因为C数组在内存中是按行顺序来存放的。所以sum2对每个数组元素的访问顺序成了这样：0， 4， 8， 1， 5， 9…… 7， 11。

但是幸运的是，一般情况下软件编程天然就是符合局部性原理的。比如程序的循环结构。

**假设CPU需要读取一个值，`int var`，而`var`在L4主存上，那么该值会被依次向上送，L4->L3->L2，但是这个传递的过程并不是单纯的只传递`var`四个字节的内容，而是把`var`所在的内存块(block)，依次向上传递，为什么要传递block？因为根据局部性原理，我们认为，与`var`值相邻的值，未来也会被引用。**

**存储器的层次结构，数据进行传送时，是以block(块)为单位传送的。在整个层次结构上，越往上，block越小而已。**

## 存储器层次结构中的缓存

归根到底，它就是一个缓存(caching)的思想，


> *这个时候可以再回头看看"图4：一个存储器层次结构的示例"*。

下面这张图和这段文字来自《深入理解计算机系统》(CSAPP)，大家可以有个更严谨和细节的认识。

![存储器层次结构中基本的缓存原理.png-58.5kB](http://static.zybuluo.com/yaowen369/yfvqbovw71fnldqqyaxcs0su/%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E4%B8%AD%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%BC%93%E5%AD%98%E5%8E%9F%E7%90%86.png)

图8：存储器层次结构中基本的缓存原理

>  存储器层次结构的中心思想：位于k层的更快更小的存储设备作为位于k+1层得更大更慢的存储设备的缓存；数据总是以块大小为传送单元（transfer unit）在第k层和第k+1层之间来回拷贝的；任何一对相邻的层次之间传送的块大小是固定的，即每一级缓存的块大小是固定的。但是其它的层次对之间可以有不同的块大小。

> 当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。如果d刚好在k层，那么就是**缓存命中**。如果第k层中没有缓存数据对象d，那么就是**缓存命不中**。当缓存不命中发生时，第k层的缓存从第k+1层 缓存中取出包含d的那个块，如果第k层的缓存已经满了的话，可能会覆盖现存的一个块。(覆盖策略可以使用常见的LRU算法)。


## `volatile` 关键字

"图4：一个存储器层次结构的示例"中，说的缓存结构其实对于一个单核CPU而言的，比如 对于 一个四核三级缓存的CPU，它的缓存结构是这样的。

![多核处理器缓存结构.jpg-47.8kB]( http://static.zybuluo.com/yaowen369/hbra9j9xu1vickvvfzws1hqk/%E5%A4%9A%E6%A0%B8%E5%A4%84%E7%90%86%E5%99%A8%E7%BC%93%E5%AD%98%E7%BB%93%E6%9E%84.jpg)

图9：多核处理器缓存结构

#  虚拟内存


## 物理和虚拟寻址

在访问者看来，主存就是一个有M个字节大小的单元组成的数组，每字节都有一个唯一的物理地址(Physical Address, PA)。 它的访问地址和数组一样，第一个地址为0，后面地址依次为`1,2,3-----M-2, M-1`;这叫做线性地址空间。这种自然的访问内存的方式我们称之为**物理寻址(physical addressing)**。

![一个使用物理寻址的系统_10.jpg-34.4kB](http://static.zybuluo.com/yaowen369/34wjbt1gqwk6zp37ggypoe7j/%E4%B8%80%E4%B8%AA%E4%BD%BF%E7%94%A8%E7%89%A9%E7%90%86%E5%AF%BB%E5%9D%80%E7%9A%84%E7%B3%BB%E7%BB%9F_10.jpg)

图10：一个使用物理寻址的系统

上图是一个物理寻址的示例，这是一条加载指令，它读取从物理地址4开始的4个字节，CPU通过内存总线，将指令和地址传递给主存，主存读取从物理地址4处开始的4个字节，返回给CPU。

早期计算机使用物理寻址方式，但是到了现在的多任务计算机时代，普遍使用的是**虚拟寻址(virtual addressing)**。如下图所示：

![一个使用虚拟寻址的系统_11.png-178.6kB](http://static.zybuluo.com/yaowen369/ybixxy3uv86id411x9i3q6ci/%E4%B8%80%E4%B8%AA%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E5%AF%BB%E5%9D%80%E7%9A%84%E7%B3%BB%E7%BB%9F_11.png)

图11：一个使用虚拟寻址的系统

CPU 通过一个**虚拟地址（virtual address,VA）**来访问主存，这个虚拟地址在被送到主存之前会先转换成一个物理地址。将虚拟地址转换成物理地址的任务叫做**地址翻译（address translation）**。

地址翻译需要 CPU 硬件和操作系统之间的配合。 CPU 芯片上叫做**内存管理单元（Menory Management Unit, MMU）**的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。


## 进程地址空间

![进程地址空间-12.png-228.3kB](http://static.zybuluo.com/yaowen369/p162llh8uz96xzt9s3nd8xo2/%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4-12.png)
图12:进程地址空间

## 虚拟内存也是一种缓存思想
**虚拟内存将主存看成是一个磁盘的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。**

从概念上来说，虚拟内存被组织成为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组，也就是字节数组。每个字节都有一个唯一的虚拟地址作为数组的索引。虚拟内存的地址和磁盘的地址之间建立影射关系。磁盘上活动的数组内容被缓存在主存中。在存储器层次结构中，磁盘(较低层L5，参见我们上篇文章图4)的数据被分割成块(block)，这些块作为和主存(较高层,L4)之间的传输单元。主存作为虚拟内存(或者说磁盘)的缓存。

虚拟内存（VM）系统将虚拟内存分割成称为大小固定的虚拟页（Virtual Page,VP），每个虚拟页的大小为 $P=2^p$ 字节。同样的，物理内存被分割为物理页（Physical Page,PP）,大小也为 $P=2^p$字节（物理页也称作页帧，page frame）。

在任意时刻，虚拟页面都分为三个不相交的部分：

+ **未分配的(Unallocated)**：VM 系统还未分配（或者创建）的页，未分配的页没有任何数据和它们关联，因此不占用任何内存/磁盘空间。
+ **缓存的(Cached)**：当前已缓存在物理内存中的已分配页。
+ **未缓存的(UnCached)**：该页已经映射到磁盘上了，但是还没缓存在屋里内存中。

![VM使用主存来作为缓存-13.png-44.8kB](http://static.zybuluo.com/yaowen369/h411wtf33dggpo336exkka1s/VM%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%AD%98%E6%9D%A5%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98-13.png)

图13：VM使用主存来作为缓存

上图展示了在一个有 8 个页面的虚拟内存中，虚拟页 0 和 3 还没有被分配，所以在磁盘上不存在。虚拟页 1，4，6 被缓存在物理内存中。虚拟页 2，5，7 已经被映射分配了，但是还没有缓存在主存中。


## 页表(page table)

系统必须得有办法判定某个虚拟页是否缓存在主存的某个地方。这具体可分为两种情况。

+ 已经在主存中，就需要判断出该虚拟页存在于哪个物理页中。
+ 不在主存中，那么系统必须判断虚拟页存放在磁盘的哪个位置，并且在物理主存中选择一个牺牲页，并将该虚拟页从磁盘复制到 主存，替换这个牺牲页。

这些功能由软硬件联合提供，包括操作系统，CPU中的**内存管理单元（Memory Management Unit,MMU）**和一个存放在物理内存中叫**页表（page table）**的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换成物理地址时都会读取页表。

![页表-14.png-76.5kB](http://static.zybuluo.com/yaowen369/vx24nahkeijwh26igzcmma9z/%E9%A1%B5%E8%A1%A8-14.png)

图14：页表

上图展示了一个页表的基本结构，页表就是一个**页表条目（Page Table Entry,PTE）**的数组。虚拟地址的每个页在页表中都有一个对应的PTE。在这里我们假设每个 PTE 是由一个有效位（Valid bit）和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 主存 中。

+ 有效位为 1，则主存缓存了该虚拟页。地址字段就表示主存中相应的物理页的起始位置。
+ 有效位为 0，则地址字段的null表示这个虚拟页还未被分配，否则该地址就指向该虚拟页在磁盘上的起始位置。

## 页命中与缺页
> 磁盘与主存之间的缓存不命中代价肯定大的多。因为L0-L4之间，每级缓存的速度大约相差10倍左右，但是L4主存与L5磁盘之间，它们的速度相差约十万倍。所以主存与磁盘之间交换的页容量是最大的，尽可能的增加命中率。相应的替换策略，操作系统也使用了更加复杂精密的算法。

当CPU想要读取包含在某个虚拟页的内容时，如果该页已经缓存在主存中，也就是**页命中**。但是如果该页没有缓存在主存中，则我们称之为**缺页(page fault)**

![对VP3中的字的应用会引起不命中-15.png-96.3kB](http://static.zybuluo.com/yaowen369/nm2iquifg6f4nuvmc0xk0zlq/%E5%AF%B9VP3%E4%B8%AD%E7%9A%84%E5%AD%97%E7%9A%84%E5%BA%94%E7%94%A8%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E5%91%BD%E4%B8%AD-15.png)

图15：对VP3中的字的应用会引起不命中

如上图所示，CPU 引用了 VP3 中的内容， VP3 并未缓存在主存中。系统从内存中读取 PTE3,得知 VP3 未被缓存，这会触发了一个**缺页异常**。缺页异常会调用kernel的缺页异常处理程序，该程序会选择一个牺牲页。如下图所示，牺牲页选择了存放在 PP3 中的 VP4。

![VP4被牺牲了-16.png-92.5kB](http://static.zybuluo.com/yaowen369/jxkz8mi004r7ydyhbvcqw8n3/VP4%E8%A2%AB%E7%89%BA%E7%89%B2%E4%BA%86-16.png)
图16：VP4被牺牲了

此时如果 VP4 的内容被修改了，kernel会将它复制回磁盘。接下来，kernel从磁盘赋值 VP3 到内存中的 PP3并更新 PTE3。随后返回用户进程。当异常处理程序返回时，它会重启执行导致缺页的指令，当重新执行这条指令时，因为 VP3 已经在主存中了，此时就是页命中了。

![VP3被缓存到PP3-17.png-98.5kB](http://static.zybuluo.com/yaowen369/le12vevc07iit31xll0x7bua/VP3%E8%A2%AB%E7%BC%93%E5%AD%98%E5%88%B0PP3-17.png)

图17：VP3被缓存到PP3

根据习惯性的叫法，我们在磁盘和内存之间传送页的活动叫做**交换(swapping)**或者**页面调度(paging)**。这种交换活动，只有当不命中发生时才会发生，(也就说，系统并不会将磁盘内容预存到内存中)。这种策略被称之为**按需页面调度(demand paging)**。


## 虚拟内存作为内存管理和内存保护的工具

**理所当然的，每个进程都有一个独立的页表和一个独立的虚拟地址空间**

每个C程序都要调用的 `stdio`这个库，不可能为每个进程都添加一份库，内存中只有一份`stdio`库的内容，供每个使用该库的进程共享。

![共享页面-18.jpg-37.4kB](http://static.zybuluo.com/yaowen369/rteqhxa79gkmaan125nulnsf/%E5%85%B1%E4%BA%AB%E9%A1%B5%E9%9D%A2-18.jpg)

图18：共享页面

如上图所示: 第一个进程的的页表将 VP2 映射到 某个物理页面。而第二个进程同样将它的 VP2 映射到 该物理页面。所以该物理页面都被两个进程共享了。

#### 内存保护

**地址翻译机制**可以使用一种自然的方式来提供内存的访问控制。PTE 上添加一些额外的控制位来添加权限。每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE 。

![虚拟内存提供内存保护-19.png-30.4kB](http://static.zybuluo.com/yaowen369/vzpgscdlyrsjxatdr7sihqle/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E6%8F%90%E4%BE%9B%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4-19.png)

图19：虚拟内存提供内存保护
在上图中，每个 PTE 额外添加了三个控制位， SUP 位表示进程是否必须运行内核模式，READ和WRITE位分别控制页面的读写权限。如果有指令违反了这些控制权限，那么 CPU 会触发一个故障，并将控制传递给内核中的异常处理程序。该种异常一般称为**段错误(segmentation fault)**。

## 段 和 页
页是操作系统为了管理主存方便而划分的，对用户不可见。
段是信息的逻辑单元，是根据用户需求而灵活划分的，所以大小不固定，对用户是可见的，提供的是二维地址空间。

##  swap分区的作用
Swap空间的作用可简单描述为：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。


## 百度百科上对于**虚拟内存**的解释非常混乱
[百度百科](https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98)
[维基百科](https://zh.wikipedia.org/wiki/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98)


> 注意：虚拟内存不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充内存级别以使其包含硬盘驱动器而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过覆盖或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对地址空间的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。













