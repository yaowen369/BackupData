# 内存是什么 - 一

标签（空格分隔）： 未分类

---


[TOC]

首先给大家讲个段子：
> 2015年开网吧，买了 DDR4 8g 内存条400多根，一根180块，今年2017年，网吧赔了20多万，昨天我把网吧电脑全卖了。内存条600一根，居然赚回了我开网吧的钱，感谢三星，感谢人民，感谢党。。。


今年以来，内存条价格暴涨，已经跃升为新的新一代理财产品，所以今天就和大家讨论一下内存的话题，主要内容就是在程序运行过程中，内存起到了什么作用。

我们先来讨论：计算机的运行究竟是在做什么？来看一下经典的冯诺依曼结构。计算机科学虽然飞速发展了几十年，但是依旧遵循冯诺依曼结构。

## 冯诺依曼结构


![冯诺依曼结构.jpg-23.2kB](http://static.zybuluo.com/yaowen369/3fogjrhuxfskrh69yrh1p7we/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E7%BB%93%E6%9E%84.jpg)
图1：冯诺依曼结构

数学家冯诺依曼提出的 体系结构包含以下几个要点：

> + 把程序本身当作数据来对待，程序和该程序处理的数据用同样的方式储存。
> + 计算机的数制采用二进制。
> + 计算机应该按照程序顺序执行。

我们根据这张图进行思考就可以得到一个结论，所谓计算机处理任务，就是根据输入内容，数据/程序从存储器送往CPU进行处理，然后再将结果输出。

本文讨论的主要内容，就是 关于存储器部分，为什么计算机需要存储器部分？这是显而易见的，我写好了程序,或者下载了一部电影，肯定得有个地方放啊。这样今后需要的时候，才能运行程序或者看电影啊。

> 关于程序与数据，数据就是一首MP3歌曲， 程序就是用来控制解析播放这首歌的代码，从底层来讲就是供CPU运行的指令.总之在计算机当中他们都是0和1，**不过方便起见，在行文中我们直接简称为数据或程序或指令， 其实都是一个意思，毕竟它们的0和1组成的流**，这个可以根据上下文来理解。

计算机体系中的这个存储器，必须得有一个特性，那就是不管有电没电，数据都得存在，不能丢失，否则一断电下载的那部电影没了，这就很坑爹了。

所以这个存储器其实就是电脑中的磁盘。用来存储我们的数据，即使掉电后，数据也不会丢失。
> 为了行文方便，文中直接将存储器用磁盘来代替了，一来大家对磁盘比较熟悉，二来磁盘也的确是最常见的存储设备。类似flash，SD卡，ROM等存储设备，其实从广义上来讲，也可以称为磁盘。因为它们的作用都是存储数据，掉电后不丢失。(这在下面文章中也会讨论到)

> 磁盘和硬盘什么关系呢？理解成一个意思也没啥错。硬盘是最常见的磁盘种类。只是在很早之前，计算机使用**软盘**存储数据，所以那种软盘也可以被称为 磁盘，不过现在软盘都早就被历史淘汰了，(电脑硬盘分区从C盘开始，就是因为AB盘是之前软盘的编号)。所以现在我们说磁盘，直接理解成硬盘就好了。

> 在我们软件当中，有个概念叫做**数据持久化**，意思就是说将数据存储起来，掉电之后不丢失，这其实就是存储在磁盘上面。

所以现在我们理解的程序就是这样，将数据从磁盘送往CPU，供CPU进行计算。

> 因为我们这片文章本来的内容就是 讨论 内存，存储等问题，所以关于 什么输入设备，输出设备之类的，就不再涉及和讨论。

然后呢，我们再简短来讨论CPU的发展历史。

大家知道，世界上第一台计算机是1946年在美国诞生的ENIAC，这个重达30吨的庞然大物，每秒可以执行5000次加法，这在当时看来，已经是个很神奇的速度了。作为人类标准意义上计算机的起源，ENIAC使用的电子管。电子管不仅体积太大，而且容易坏。在五十年代，贝尔实验室发明了晶体管。*(就是那个 牛逼哄哄，共获得过八项诺贝尔奖的贝尔实验室。贝尔实验室注定是要名垂青史的)。*这个时候晶体管依旧比较大，然后后来TI的工程师又发明了集成晶体管。再后来IBM研发成功 首款使用集成电路的计算机,**IBM360**, 然后后来 就是**仙童八叛徒**与intel，AMD的故事了。这是IT历史上很著名的历史，这里就不再累述了。伴随着世界上第一款商用处理器：Intel4004的出现，波澜壮阔的**摩尔定律**开始了。

> 当时为IBM 360 研发操作系统时的那个项目经理，根据这个系统的研发经验， 后来写了一本经典著作《人月神话》,也有项目的其他一些参与者根据这个项目经验，立传出书了，当时搞计算机的 那批人，真的个个都是大神啊。

**当价格不变时，集成电路上可容纳的元器件的数目，约每隔18-24个月便会增加一倍，性能也将提升一倍。**

半导体行业开始腾飞了。具体到CPU上来说，就是CPU上集成的晶体管数量越来越多。 看新闻也可以看到，CPU的工艺逐步有24nm，到20nm，到16nm，目前貌似到了10nm。所以CPU的执行速度也越来越快。

> 当然，摩尔定律也快到尽头了，因为根据量子力学，2nm是理论极限值。线宽不能再细了，低于2nm，隧穿效应就会产生干扰。

上面一段闲扯了一段CPU的发展历史，总之，现在的CPU集成度越来越高了，速度也越来越快了。每秒钟能执行的指令也越来越多。(如果不知道指令,汇编之类的，可以看一下我的的另一篇文章[关于跨平台的一些认识](http://www.cnblogs.com/yaoxiaowen/p/7470460.html))。

CPU的作用，就是去执行指令，并且尽可能的以最快的速度去执行指令，那它具体是怎么执行的呢，做过单片机或者学过微机原理的应该比较清楚。就是伴随着时钟周期的滴滴答答的节奏，CPU来执行指令。

至于那些指令是什么，这些就是Intel的架构师们去设计的了，CPU认识这些指令，并且能执行运算。(别忘记了冯诺依曼体系结构那张图)。对于那些指令,但是CPU采取了各种措施来加快执行过程(就是加快它的运算速度)。比如有以下几种常见的措施：

> + **流水线(pipeline)技术**：去电子厂打过工的同学肯定很熟悉这个流水线。CPU的流水线的工作方式就像工业生产上的装配流水线。比如 CPU中由5—6个不同功能的电路单元组成一条指令处理流水线，然后将一条指令分成5—6步后再由这些电路单元分别执行。在执行过程中，将指令源源不断的送往CPU的运算器。让每个电路单元都不闲着，这样就大大的加快了执行的执行速度。(当然，有些CPU会将指令的执行过程分解的更细)

> + **超线程(Hyper-Threading)技术**:对于超线程，百度百科的解释我都看不懂，但是大概原理就是这样的。CPU在进行线程切换的时候，要有保存寄存器状态，PC值等操作。把他们写会缓存中保存。并且把另一个线程的相关内容送到寄存器上。(pc是program count，CPU的一个部件，可不要理解为个人电脑)。这个过程是必不可少的，否则待会再把这个线程切换回来时，不知道该线程的各个状态， 那还怎么接着继续执行呢？ 也正因为如此，所以这个过程比较慢，大概需要几万个时钟周期。所以后来就做了这样的设计，把寄存在，PC啊之类的控制器做两套。这样CPU在执行A线程时，使用的第一套寄存器之类的，想要切换到B线程，直接从第二套寄存器那边来获取数据，这样不就快了很多嘛，CPU的运算单元不用再傻傻的等着着寄存器值的切换过程。因为对于我们这些通用性CPU，线程切换是个非常频繁的操作，所以使用了该技术就会节省大量的时钟周期。也就相当于加快了CPU的执行速度。这就是那些CPU的参数中所谓的*四核八线程*的由来，就是他们使用了超线程技术。(当然，CPU的面积很小，你每个核多做一套控制器固然会占用宝贵的控件，但是它带来的优点肯定是大于缺点的)。


> + **超标量技术**:CPU可以在每个时钟周期内执行多个操作,可以实行指令的并行运算。

> + **乱序执行**: 我们认为程序都是顺序执行的。但是在CPU层面上，指令的执行顺序并不应要与它们在机器级程序(理解成汇编就好)中顺序一样。比如 我的代码如下`a = b+c;  d++;`这两个语句 它不按照顺序执行也不会影响最终结果。当然这只是在CPU执行指令的层面，在程序员们看来，依旧认为程序是顺序执行的。

前面扯了那么多，目的只有一个。虽然每条指令的执行可能几个时钟周期到几十个时钟周期不等。但是CPU采用了种种技术来加快这个执行过程。所以其实总体算起来，平均每个时钟周期都可以执行一条指令。而现在CPU集成度如此之高，主频都那么高。比如 intel 的i7 7700K主频都达到了 4.2G。这也就意味着，这个处理器每秒钟可以执行4.2亿个 指令。

总之一句话。

##### **CPU每秒钟可以执行几亿个指令，所以它的执行速度真丫的的快啊**

我们讨论完CPU如此快的执行速度，我们再来说我们常见的存储设备-机械硬盘。



![机械硬盘结构.jpg-90.4kB](http://static.zybuluo.com/yaowen369/qb1nhqgk1kqwbemlip2akjll/%E6%9C%BA%E6%A2%B0%E7%A1%AC%E7%9B%98%E7%BB%93%E6%9E%84.jpg)

图2：机械硬盘结构

机械硬盘的结构这里就不再具体的讨论了。它让我想起了民国电影中，那种播放音乐的唱片机。

> 知道了机械硬盘的结构，自然也就明白了安装了机械硬盘的电脑，使用过程中，如果机箱被摔了，那么可能后果很严重，因为会把机械硬盘的那个读写头/传动臂等机械结构摔坏。

机械硬盘也算是一种精密的产品，它可以做的容量很大(现在京东上买的电脑硬盘容量很多都是1T了)，我们的数据是存储在磁盘上的，所以CPU要想执行指令/数据，就要从存储单元，也就是磁盘上读取， CPU可以一秒钟执行几亿条指令，但是相对之下，磁盘的读写速度就是慢如蜗牛了。假设磁盘一秒钟可以读取100条指令。那么这中间就存在 巨大的差异。半导体行业发展了几十年，终于将CPU的执行速度提高了那么快，奈何磁盘技术发展的太不给力了。那些设计研究CPU的科学家们一口老血吐在在了芯片上，CPU再快，可是磁盘严重拖后腿，那CPU就相当于工作严重不饱和，如果直接从磁盘上 来读取数据，那么CPU相当于 99.9999%的时间都在闲置着。


> "假设磁盘一秒钟可以读取100条指令。":带有假设字样的，具体数字都是随便写的。比如 磁盘读写速度自然有它的参数指标，不过我们只是为了说明问题， 所以能理解其中的道理就好。但是其中说明的道理，自然是无误的。

当然，做磁盘的那些大牛们也在争取进步，比如 现在SSD(固态硬盘)，它的速度就比 机械硬盘快了一二十倍吧。但是对于CPU的速度，这也是然并卵啊。

所以这就是个大问题。

#####  **我们的目标就是执行任务时让CPU全负荷的运行，争取对于任意一个时钟周期，CPU都不会闲置浪费。**
这就像是老板对我们这些员工的要求一样。老板给我们发工资， 那么他就是希望我们每一分每一秒甚至每一毫秒都在努力帮公司干活。不要有什么任何时间闲着。所以我们要感谢劳动法，让我们每天工作八小时就够了。我们也是人，也需要吃喝拉撒，所以虽然老板的希望很美好，员工们实在做不到啊。

> 看到劳动法说每天工作八小时就够了，程序猿们哭晕在厕所。

> 程序猿问科比：“你为什么这么成功？ ”
科比：“你知道洛杉矶凌晨四点是什么样子吗？ ”
程序猿：“不知道，一般那个时候我还没下班呢，怎么了？”
科比：“额…….”


通过上面的介绍，我们就明白了计算机体系的主要矛盾，CPU太快了，而磁盘太慢了。所以它俩是不能够直接联系的，我们可以加一层过度。这就是内存的作用。这就是本文开头那个今年跃升为新一代理财产品的内存条的作用和功能。

而实际上，内存的读写速度，比磁盘快几十万倍。所以它终于够资格和CPU直接通信了。

这里有张图，我们来看一下磁盘/内存,与CPU速度之间逐渐增大的差距。

![磁盘DRAM和cpu速度之间逐渐增大的差距.png-122.1kB](http://static.zybuluo.com/yaowen369/rlrofelzhskff53mrhm0ud8v/%E7%A3%81%E7%9B%98DRAM%E5%92%8Ccpu%E9%80%9F%E5%BA%A6%E4%B9%8B%E9%97%B4%E9%80%90%E6%B8%90%E5%A2%9E%E5%A4%A7%E7%9A%84%E5%B7%AE%E8%B7%9D.png)

图三：磁盘DRAM和cpu速度之间逐渐增大的差距

所以现在这个程序执行过程就变成了这样子。CPU执行指令时，从内存直接获取或写回。而内存当中的数据呢，又来自于 磁盘。

> 提到添加过渡层。这其实和JVM的原理都是类似的。具体可参考我的另一篇文章[关于跨平台的一些认识](http://www.cnblogs.com/yaoxiaowen/p/7470460.html)。也许这就是大道至简吧。


## 存储器层次结构

我们这里说的内存，主要是指主存。就是几百块一条的那个内存条。虽然它的读写速度比磁盘快了很多。但是相对于CPU的速度依旧还是慢。那么我们在主存和CPU之间，完全可以再加速度更快的缓存层。所以intel i7的存储器层次结构是这样的。

![一个存储器层次结构的示例.jpg-111.3kB](http://static.zybuluo.com/yaowen369/nuqqmsxxh7pxnfisubmzg8qq/%E4%B8%80%E4%B8%AA%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E7%9A%84%E7%A4%BA%E4%BE%8B.jpg)

图4：一个存储器层次结构的示例


我们在这篇文章中，前面扯了那么多篇幅，就是告诉你，我们为什么需要内存(主存),那么理解了主存，自然也就理解了L3，L2，L1等各级缓存存在的意义。并且对于本地磁盘来讲，它也相当于 服务器的缓存。因为我们从网上下载数据/文件时，速度明显比从本地磁盘读取要慢。

一般情况下，L5与L4速度相差几十万倍， 而L3-L0之间，它们每级缓存的速度差异大概是10倍。

记住一点就行了。CPU执行速度实在太快了，一秒钟执行几亿个指令，CPU干活干脆利落，那么存储器就要想方设法的用最快的速度把指令/数据 送给CPU去运行。否则CPU干活再快，又有什么意义呢。

基本思想已经理解了。那么我们就开始具体讨论细节问题。

## RAM，ROM，总线等
看看上面那幅图，什么SRAM，DRAM，还有我们前面讲的SSDM，Flash，机械硬盘等，还有下面要讨论的总线(BUS),在这一部分，我们先来讨论一些基础硬件知识.

首先，他们都是属于存储器，可以把他们分为两类，
1. **易失性(volatile)存储器**:这就是我们说的内存，SRAM等，特点是读写速度很快，但是掉电了，那么所有的数据都丢了。
2. **非易失性(nonvolatile)存储器**：这些就是我们说的磁盘，Flash，光盘等。读写速度虽然慢，但是优点也是大大的。 但是人家没电时，数据也可以保存，也不会丢失。

+ **RAM(Random-Access Memory)**:随机访问存储器。易失性存储器。也可以访问两类：**SRAM(静态的)和DRAM(动态的)**,并且SRAM的读写速度比DRAM更快，当然价格也更贵。
+ **ROM(read-only memory)**：只读存储器，非易失性存储器。特别注意这个名字容易让人产生误解，虽然它的名字叫做read-only，但是它既可以读，也可以写，这么只叫是因为历史原因。（最开始的ROM，读速度比较快也比较容易，但是写就很麻烦很慢，所以就叫做read-only了）。

ROM相比于RAM，容量也更大。价格也便宜了许多。 但是RAM的读写速度则是快了许多。

+ **闪存(Flash memory)**：它也是非易失性存储器。我们常说的 SSD，SD卡都属于Flash技术，如果从概念上来讲，他们都属于ROM，这类存储器经常用在手机，相机，pad等电子设备上。而机械硬盘常用在PC上。因为机械硬盘比较属于机械机构，体积太大了，自然没办法用在手机上，不过人家价格便宜， 存储容量大的特点比较适用PC，服务器上。

其实我觉的把 Flash，ROM等都叫做磁盘，也没什么错。毕竟它们的作用和概念都是相似的，都是非易失性存储器，都是用来保存数据，掉电后也不丢失。区别只是他们各自使用的半导体技术不同而已。Flash芯片等基于集成芯片的存储器读写速度比机械硬盘快，不过价格也比后者贵的多。

[TODO](http://www.yaoxiaowen.com/)
DRAM

所以理解了这些常见存储器技术的区别。再来看看 上面那张 图，也许就理解更深刻了。

那张图，越往上，读写速度越快，但是也更贵。(淘宝上搜搜8G的内存条价格，再看看256G的SSD，1T的机械硬盘都是啥价格，就明白了)。像L0 寄存器级别，CPU的读取寄存器的值耗费的时钟周期为0个。所以这真是速度的极致了。

另外，我们在电脑的主板上可以看到内存条(L4主存)。硬盘（L5），但是为啥没见到所谓的L3-L0了。原因很简单，他们都是集成在CPU芯片内部的。



并且这样是 intel i7的处理器，所以有三级缓存，要是差一些的处理器，比如 i3之类的， 就只有两级缓存了。但是它们的思想总是相同的。

我们知道了存储器的层级结构，下面还有一个问题，就是怎么把硬盘，内存条之类的连接起来进行通信呢，这就是 总线(Bus)了。

![一个典型系统的硬件组成.jpg-91.1kB]( http://static.zybuluo.com/yaowen369/haeo9qrhslmn280ayp18v0wb/%E4%B8%80%E4%B8%AA%E5%85%B8%E5%9E%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A1%AC%E4%BB%B6%E7%BB%84%E6%88%90.jpg)

图6：一个典型系统的硬件组成

注意图中存在三条总线，IO总线，存储器总线(通常称为内存总线)，系统总线。如果在PC主板上，它那就是那一排并行的32/64根并行的导线。这些导线用来连接CPU，内存，硬盘，以及USB控制器等。CPU与存储器，输入设备，输出设备等通信，都是通过总线。不同总线的速度自然也有差异。

> 因为我们这片文章是讲软件的，所以关于硬件部分，就一笔带过，读者知道有这回事就ok了。总线上携带地址，数据和控制信号， 如何区分不同信号，又怎么知道这个信号是连接显示器的，还是连接键盘或磁盘的，这就是另外一个问题了。

> CPU为什么要通过所谓的I/O桥(就是所谓的北桥/南桥芯片组)与存储器和IO设备连接，这是因为CPU的主频太高了，它的时钟周期一秒钟震荡几亿次，而存储器等这些外围设备的时钟周期都没那么快，所以他们不能直接通信。


## 不管中间怎么加缓存，但是数据从硬盘到内存的速度就是那么慢，那么这些缓存意义何在？

有些读者脑子转的比较快，可能想到了这样一个问题。
> 不管你中间怎么加缓存，也不管中间的什么SRAM，DRAM的读写速度有多快，但是磁盘的读写速度就是那么慢，所以磁盘与主存之间的交互，就是那么慢。所以CPU需要向磁盘读写一个数据。它速度的瓶颈就是在磁盘那里，这个根本快不了，那么加那么多缓存，意义有何在呢？

首先这是一个好问题啊。 让我们下面继续讨论，来慢慢的理解这个问题的答案是什么。

我们来看看，CPU如何读取磁盘中的一个数据。

![读一个磁盘扇区-1.png-27.6kB](http://static.zybuluo.com/yaowen369/fb5u30z7wb0uvlh493pq23mx/%E8%AF%BB%E4%B8%80%E4%B8%AA%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA-1.png)



![读一个磁盘扇区-2.png-138.1kB](http://static.zybuluo.com/yaowen369/wg1kuwuowflv7xnj9o8sqg7x/%E8%AF%BB%E4%B8%80%E4%B8%AA%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA-2.png)

图7：读一个磁盘扇区


网上找的图片不是很清楚，注意三张图中的黑线。步骤主要分为三部：
> 1. CPU 将相关的命令和地址，通过系统总线和IO总线传递给磁盘，发起一个磁盘读。
> 2. 磁盘控制器将相关的地址解析，并通过IO总线与内存总线将数据传给内存。
> 3. 该过程完成之后，磁盘控制器向CPU发送一个中断信号。(学电子的同学应该很清楚的知道中断是什么)。这时CPU就知道了，我刚才想要的数据已经发送到内存了。

我们可以确认，第二步磁盘操作很慢，但是问题的关键是在于在第一步时，CPU参与了。但是第二步和第三部时，CPU根本不参与啊。第二步很耗时，但是CPU在这个时间完全在干其他时间啊。此时它线程已经切换了。再执行另一个线程的事情啊。所以此时的CPU依旧没有闲着啊。而待第三步时，通过中断，CPU已经知道了，我要的数据已经发送到内存了，然后此时它可以将线程再切换回来，接着执行这个该线程的任务。

除了因为阻塞，而实行的多线程的切换之后，还有一点。
我先问一个问题。

```c
//@author :www.yaoxiaowen.com
int main(){
	//我们执行任务的代码
    return 0;
}
```
对于任何一个应用/进程而言，它都应该有一个入口函数。(虽然它不一定直接让我们写`main`方法)。我们在入口函数内部执行我们的代码，执行完了这个应用/进行也就结束了。这个很好理解。很多程序都是这样。比如测试工程师写的一个case。跑完了这个任务就结束了。

但是 有些程序，比如一个android app，(pc上的一个有界面的程序也是如此)。你打开了这个app。不做任何操作。这个界面会一直存在。没什么变化，也不会消失。思考一下这是为什么。因为我们刚来讲了，这个app肯定也要有一个main入口的。 (虽然我们没直接写)。main里面的代码执行完了，就应该结束了啊。一个程序的代码/指令数肯定是有限的。而这个app在我们不主动退出时，就会一直存在呢。

所以对于这个app的入口main来讲，应该是这样的。

```c
//@author :www.yaoxiaowen.com
int main(){
	boolean flag  = true;
	while (flag){
		//我们执行任务的代码
	}
    return 0;
}
```

并且不只是这个app的入口函数，在一个程序内部，其实也有很多for，while循环语句。
那么当我们把这些相关的指令送到了主存，或者更高一级的缓存当中时，那么CPU在需要执行这些指令时，存取速度自然快了很多。

**在执行一个程序时，启动阶段是比较慢的，因为需要从磁盘读取数据。(而CPU在这个阶段根本不会干等着，它切换线程去干其他事情了)。 但是数据被送往内存之后，它执行起来就会快多了，并且伴随着执行过程，还可能越来越快，因为这些数据，有可能被一级一级的向上送，从L4，送到L3，再送到L2，L1**

so，上述那个问题的答案，已经解释的比较清楚了吧。


## 局部性原理(Principle of locality)
locality对于硬件和软件系统的设计和性能都有着重要的影响。对于我们理解存储器的层次结构也有重要影响。所以我们来讨论一下局部性原理。

**程序倾向于引用临近于与其他最近引用过的数据项的数据项。或者最近引用过的数据项本身。**这种倾向性，我们称之为局部性原理。它通常有以下两种形式：

> + 时间局部性(temporal locality):时间局部性指的是：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。

> + 空间局部性(spatial locality):如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。


一般而言，**优良好局部性的程序比局部性差的程序运行的更快。** 现代计算机系统的各个层次，从硬件到操作系统、再到应用程序，它们的设计都利用了局部性。

当然，光说理论的东西是比较玄乎的。我们来看实际的例子。

```c
//@author www.yaoxiaowen.com
int sum1(int array[N])
{
    int i, sum = 0;
    for(i = 0; i < N; i++)
        sum += array[i];
    return sum;
}
```
在这个程序中，变量`sum`,`i`在每次循环迭代时被引用一次，因此对`sum`和`i`来说，有较好的时间局部性。
对变量`array`来说，它是一个int类型数组，循环时按顺序访问`array`，因为一个数组在内存中是占用连续的内存空间。因而的较好的空间局部性，


再来看一个例子：
```c
//@author www.yaoxiaowen.com
int sum2(int array[M][N])
{
    int i, j, sum = 0;
    for(i = 0; i < M; i++){
        for(j = 0; j < N; j++)
            sum += array[j][i];
    }   
    return sum;
}
```

这是一个空间局部性很差的程序。
假设这个数组是`array[3][4]`,因为C数组在内存中是按行顺序来存放的。所以sum2对每个数组元素的访问顺序成了这样：0， 4， 8， 1， 5， 9…… 7， 11。所以它的空间局部性很差。

但是幸运的是，一般情况下软件编程天然就是符合局部性原理的。比如程序的循环结构。

**假设CPU需要读取一个值，`int var`，而`var`在L4主存上，那么该值会被依次向上送，L4->L3->L2，但是这个传递的过程并不是单纯的只传递`var`四个字节的长度，而是把`var`所在的内存块(block)，依次向上传递，为什么要传递block？因为根据局部性原理，我们认为，与`var`值相邻的值，未来也会被引用。**


## 存储器层次结构中的缓存

以上的内容，洋洋洒洒的扯了那么多，我相信对于所谓的 **存储器层次结构**读者应该有一个基本的认识，有些文字虽然不是很严谨，但是本文的主要目的也就是让大家理解基本思想。

归根到底，它就是一个缓存(caching)的思想，并且其实不复杂，

> 比如，我们做app开发的，对于app中的那些可能需要动态改变的图片，都是后台发给我们图片链接，我们才显示在app上，在显示这些图片时，我们总要使用 什么`Glide`,`Picasso` 等一些图片缓存框架来把下载好的图片缓存在手机本地存储上。这样如果下次打开app时，如果这个图片链接没有改变时，我们就直接拿手机本地缓存的图片来显示，而不用再从服务器上下载了。为什么要这么做。因为从服务器上下载比较慢，而手机本地存储(ROM)中读取就会快很多。
> *这个时候请读者再回头看看"图4：一个存储器层次结构的示例"*



下面这张图和这段引用文字来自《深入理解计算机系统》(就是大名鼎鼎的CSAPP)，大家可以有个更严谨和细节的认识。

![存储器层次结构中基本的缓存原理.png-58.5kB](http://static.zybuluo.com/yaowen369/yfvqbovw71fnldqqyaxcs0su/%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E4%B8%AD%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%BC%93%E5%AD%98%E5%8E%9F%E7%90%86.png)


图8：存储器层次结构中基本的缓存原理

>  存储器层次结构的中心思想：位于k层的更快更小的存储设备作为位于k+1层得更大更慢的存储设备的缓存；数据总是以块大小为传送单元（transfer unit）在第k层和第k+1层之间来回拷贝的；任何一对相邻的层次之间传送的块大小是固定的，即每一级缓存的块大小是固定的。但是其它的层次对之间可以有不同的块大小。

> 当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。如果d刚好在k层，那么就是**缓存命中**。如果第k层中没有缓存数据对象d，那么就是**缓存命不中**。当缓存不命中发生时，第k层的缓存从第k+1层 缓存中取出包含d的那个块，如果第k层的缓存已经满了的话，可能会覆盖现存的一个块。(覆盖策略可以使用常见的LRU算法)。


## `volatile` 关键字
在java和C当中，有一个`volatile`关键字，它的作用就是多线程时保证变量的内存可见性，但是具体怎么理解呢？



我们在"图4：一个存储器层次结构的示例"中，说的 缓存结构其实对于一个单核CPU而言的，比如 对于 一个四核三级缓存的CPU，它的缓存结构是这样的。

![多核处理器缓存结构.jpg-47.8kB]( http://static.zybuluo.com/yaowen369/hbra9j9xu1vickvvfzws1hqk/%E5%A4%9A%E6%A0%B8%E5%A4%84%E7%90%86%E5%99%A8%E7%BC%93%E5%AD%98%E7%BB%93%E6%9E%84.jpg)

图9：多核处理器缓存结构

我们可以看到`L3`是四个核共有的，但是`L2`,`L1`其实是每个核私有的，如果我有一个变量`var`,它会被两个线程同时读取，这两个线程在两个核上并行执行，因为我们的缓存原理，这个`var`可能分别在两个核的 `L2`或`L1`缓存，这样读取速度最快，因为两个核和他们的私有缓存它们彼此又不通信，所以 这个`var`可能就被 这两个核分别修改成不同的值， 最后将值回写到`L3`或L4主存时，那么这个值就会错误了。

所以`volatile`关键字就是防止这种情况产生，对于被`volatile`关键字的变量，每次CPU需要读取时，都至少要从`L3`读取，并且CPU计算结束后，也立刻回写到`L3`中,这样读写速度虽然减慢了一些，但是保证了多线程情况下这个值的正确性。


