#  内存是什么 - 二

标签（空格分隔）： 未分类

---

[TOC]


通过上一篇文章的扯淡，我们应该已经明白了存储器的层次结构，虽然技术细节很复杂，但是思想却不难理解，因为就是很简单的缓存思想。那么这篇文章，我们开始讨论关于内存的另一个重要领域.**虚拟内存**。其实思想也是很容易理解的。

我不知道有多少人听过虚拟内存这个概念，但是虚拟内存是计算机系统最重要的概念之一，并且它成功的主要原因就是它是一直在沉默的，自动的工作，换句话说，我们这些做应用的程序员恐怕很多根本没听过这个概念，虽然它是如此的重要。但是一个没追求的码农不是好的搬砖民工，所以作为一个有理想有抱负的程序员，我们还是要去理解**虚拟内存**，甚至可以这样说，如果不理解虚拟内存，你根本不可能理解程序的深层次运行原理。也不可能去理解汇编器，链接器，加载器，共享对象，文件和进程等概念。

千言万语汇成一句话。**共享内存是一个至关重要同时也很简单的思想。**

首先让我们思考几个问题:
> + 不管什么程序，直接(比如C)或间接(比如java)的编译的(或者最后运行的形态)结果，都是汇编。(这点不知道的，欢迎看看我的另一篇文章,[关于跨平台的一些认识](http://www.cnblogs.com/yaoxiaowen/p/7470460.html))，比如这句汇编代码：`mov eax,0x123456;`它的意思是将内存`0x123456`处的内容送往`eax`这个寄存器。我们知道，线程在某个CPU的core运行时，它的寄存器都是关于该线程的数据，线程切换了，寄存器上的数据也都是要切换。但是内存不一样啊。内存中总是充斥着各个应用的数据，各个应用的数据是共存的。那么假设有个应用，音乐播放器，它的汇编代码中，引用了`0x123456`这个内存地址。但是计算机上的应用多了去了，那其他应用编译出的汇编代码中也完全有可能引用 `0x123456`这个地址啊。那为什么竟然没起冲突和错误呢？

> + 进程是计算机领域最重要的概念之一，什么是进程？进程是关于某次数据集合的一次运行活动， 是运行在它自己地址空间的一段自包容程序， 这么说有点抽象，解释的通俗的点， 一个程序在运行时，我们会得到一个假象，该程序好像是独占地使用CPU和内存，CPU是没有间断地一条接一条的执行该程序的指令，所有的内存空间都是供我们的代码和数据分配的。(这点有点不严谨，其实内存空间还有一部分要分给`kernel`)。说起来，这个程序就好像得到了全世界一样。啊，CPU是我的，内存也全部我的，天下的妹子们也都是我的。当然，我们都知道这只是进程所提供的假象而已。另外，我们说线程没有自己的地址空间，它只是使用了父进程的地址空间，那么这些都是什么意思？或者说，怎么理解，怎么做到的？

> + 很多程序中，都会引用库API，比如每个C程序都要引用`printf()`，这句代码所在的`stdio.h`库，在程序运行时，明显的也要被加入内存，那问题是这么多程序都引用了这个库，难道我内存中需要加很多份吗？傻子都知道这明显不可能啊，照着这种做法那内存早就爆掉了，那么这个库又是怎么被所有程序共享的呢？

这些让我们细思恐极的疑问，都将通过这篇文章来给大家解答。


## 物理和虚拟寻址


在访问者看来，主存就是一个有M个字节大小的单元组成的数组，每字节都有一个唯一的物理地址(Physical Address, PA)。 它的访问地址和数组一样，第一个地址为0，后面地址依次为`1,2,3-----M-2, M-1`;这叫做线性地址空间。这种如此自然的访问内存的方式我们称之为**物理寻址(physical addressing)**。

> 注意：在访问内存时，**对于任意一个地址，(不管是第0个还是第M-1个)，访问时间总是相同的**。大概原因是因为内存芯片是晶体管的电子信号转化(具体原因我这个做软件的也解释不清楚，也没必要解释清楚)。

> 在各种数据结构中，我们都说hash表是最快的，比什么红黑树，B+树都要快，那hash表为什么最快？那是因为hash表内部本质上是因为使用数组的。说白了，还是数组最快，那数组为什么最快？数组最快，就是因为我们知道了数组的起始地址，就可以知道数组中任意一个元素的地址，而对于内存，访问任意一个地址，访问时间总是相同的。(不过好的hash算法还是很难设计的， 不过这是另外一个话题了)。


![一个使用物理寻址的系统_10.jpg-34.4kB](http://static.zybuluo.com/yaowen369/34wjbt1gqwk6zp37ggypoe7j/%E4%B8%80%E4%B8%AA%E4%BD%BF%E7%94%A8%E7%89%A9%E7%90%86%E5%AF%BB%E5%9D%80%E7%9A%84%E7%B3%BB%E7%BB%9F_10.jpg)

图10：一个使用物理寻址的系统

上图是一个物理寻址的示例，这是一条加载指令，它读取从物理地址4开始的4个字节，CPU通过内存总线，将指令和地址传递给主存，主存读取从物理地址4处开始的4个字节，返回给CPU，CPU将其存放在一个寄存器中。

> 因为这篇文章主要讨论 虚拟内存，这是关于L4级主存和磁盘之间的交互，所以文章中有时候说内存代指主存。所以这些不要误以为是L1，L2之类的缓存。如果看不懂这段话啥意思，务必看看我的上一篇文章[TODO](http://www.yaoxiaowen.com/),然后再来看这篇文章。 

早期的计算机使用的这样的物理寻址方式，但是到了现在的多任务多进程的时代，普遍使用的是**虚拟寻址(virtual addressing)**。如下图所示：


![一个使用虚拟寻址的系统_11.png-178.6kB](http://static.zybuluo.com/yaowen369/ybixxy3uv86id411x9i3q6ci/%E4%B8%80%E4%B8%AA%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E5%AF%BB%E5%9D%80%E7%9A%84%E7%B3%BB%E7%BB%9F_11.png)

图11：一个使用虚拟寻址的系统

CPU 通过一个**虚拟地址（virtual address,VA）**来访问主存，这个虚拟地址在被送到主存之前会先转换成一个物理地址。将虚拟地址转换成物理地址的任务叫做**地址翻译（address translation）**。

地址翻译需要 CPU 硬件和操作系统之间的配合。 CPU 芯片上叫做**内存管理单元（Menory Management Unit, MMU）**的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

> 有少数现代的计算机系统依旧在使用物理寻址方式，比如DSP，嵌入式系统，超级计算机系统。因为这些系统的主要任务是执行单一的任务，不像通用性计算机那样需要执行多任务。可以想象到，物理寻址方式更快。这个道理和[关于跨平台的一些认识](http://www.cnblogs.com/yaoxiaowen/p/7470460.html)文章中，理论上java比C++慢的道理是一样的。

前面解释完虚拟地址，那么关于文章开头时提的那些疑问，可能有些人心里面都有数了。因为那些地址都是虚拟地址，并非真实的物理内存当中的地址。基本思想已经懂了，那么剩下的我们就更具体的讨论细节。

## 进程地址空间

![进程地址空间-12.png-228.3kB](http://static.zybuluo.com/yaowen369/p162llh8uz96xzt9s3nd8xo2/%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4-12.png)
图12:进程地址空间

上图是一个64位的进程地址空间，编译器在编译程序时，将结果编译成32/64位的地址空间。正是因为虚拟寻址的存在，大大的简化了编译器，链接器的工作。同样也因为虚拟内存，每个进程才能有很大的，一致的，私有的的地址空间。这方便了内存管理，保护了每个进程的地址空间不被其他进程破坏。同时也方便了共享库。

## 虚拟内存也是一种缓存思想
**虚拟内存将它将主存看成是一个存储在磁盘空间上的地址空间的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。**

从概念上来说，虚拟内存被组织成为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组，也就是字节数组。每个字节都有一个唯一的虚拟地址作为数组的索引。该过程叫做**内存影射**。磁盘上活动的数组内容被缓存在主存中。在存储器层次结构中，磁盘(较低层，我们上篇文章图4的L5)的数据被分割成块(block)，这些块作为和主存(较高层,L4)之间的传输单元。主存作为虚拟内存(也就是磁盘)的缓存。

虚拟内存（VM）系统将虚拟内存分割成称为虚拟页（Virtual Page,VP）的大小固定的块，每个虚拟页的大小为 $P=2^p$ 字节。同样的，物理内存被分割为物理页（Physical Page,PP）,大小也为 $P=2^p$字节（物理页也称作页帧，page frame）。

在任意时刻，虚拟页面的集合都分为三个不相交的子集：

+ **未分配的(Unallocated)**：VM 系统还未分配（或者创建）的页，未分配的页没有任何数据和它们关联，因此不占用任何内存/磁盘空间。
+ **缓存的(Cached)**：当前已缓存在物理内存中的已分配页。
+ **未缓存的(UnCached)**：，未缓存在物理内存中的已分配页。

> 其中**未分配的VP**不占用任何的内存/磁盘空间，这点要理解。32位程序它的地址空间就有4G大小，至于64G的程序它的地址空间是一个非常大的天文数字(貌似是16777216T)，而我们现在的电脑磁盘能有2T就算大的了。所以如果64位的程序每个VP都要在磁盘上对应着分配实际的PP。那是无论如何也对应不上的。16777216T对2T，这自然不可能一一对应的分配。更重要的是也完全没必要,"图12:进程地址空间"中可以看到，地址空间内有大量的空白，没实际用到的地址。毕竟哪个程序，也不可能真实的占有那么大的地址啊。


![VM使用主存来作为缓存-13.png-44.8kB](http://static.zybuluo.com/yaowen369/h411wtf33dggpo336exkka1s/VM%E4%BD%BF%E7%94%A8%E4%B8%BB%E5%AD%98%E6%9D%A5%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98-13.png)

图13：VM使用主存来作为缓存

上图展示了在一个有 8 个虚拟内存的虚拟内存中，虚拟页 0 和 3 还没有被分配，所以在磁盘上不存在。虚拟页 1，4，6 被缓存在物理内存中。虚拟页 2，5，7 已经被分配了，但是当前并没有缓存在主存中。

> 当然，那个图上标注的不对,VP 部分， `n-p`和`N-1`应该分别标注为`3`和`7`,不过我们找不到更合适的图了，(这种图自己画压力太大了)。所以大家知道我们假设共有8个VP就好了。

## 页表(page table)

系统必须得有办法去判定一个虚拟页也是否缓存在主存的某个地方。这具体可分为两种情况。

+ 如果已经在主存中，那么还得判断该虚拟页存在于哪个物理页中。
+ 如果不在主存中，那么系统必须判断虚拟页存放在磁盘的哪个位置，并且得在物理主存中选择一个牺牲页，并将虚拟页从磁盘复制到 主存，替换这个牺牲页。

这些功能由软硬件联合提供，包括操作系统软件，MMU和一个存放在物理内存中叫**页表（page table）**的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换成物理地址时都会读取页表。



![页表-14.png-76.5kB](http://static.zybuluo.com/yaowen369/vx24nahkeijwh26igzcmma9z/%E9%A1%B5%E8%A1%A8-14.png)

图14：页表

上图展示了一个页表的基本结构，页表就是一个**页表条目（Page Table Entry,PTE）**的数组。虚拟地址的每个页在页表中都有一个对应的PTE。在这里我们假设每个 PTE 是由一个有效位（Valid bit）和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 主存 中。

+ 有效位为 1，则主存缓存了该虚拟页。地址字段就表示主存中相应的物理页的起始位置。
+ 有效位为 0，则地址字段的null表示这个虚拟页还未被分配，否则该地址就指向该虚拟页在磁盘上的起始位置。

## 页命中与缺页
> 我们在上一篇文章[TODO](http://www.yaoxiaowen.com/)中说过缓存命中与不命中的问题，那么都是缓存思想，在这里肯定也会存在同样的问题。并且磁盘与主存之间的缓存不命中代价肯定大的多。因为L0-L4之间，每级缓存的速度相差10倍左右，但是L4主存与磁盘之间，他们的速度相差是十万倍。所以主存缓存磁盘的页容量是最大的，尽可能的增加命中率，并且对于对应的替换策略，操作系统也使用了更加复杂精密的算法。

> 另外，在上篇文章[TODO](http://www.yaoxiaowen.com/)，每次替换的区域，我们用了**块(block)**,而这里我们却在说**页(page)**， 其实他们是同一个意思。只是因为历史原因，叫法不同罢了。




当CPU想要读取包含在某个虚拟页的内容时，如果该页已经缓存在主存中，也就是**页命中**。perfect,很完美。但是如果该页没有缓存在主存中，则我们称之为**缺页(page fault)**

![对VP3中的字的应用会引起不命中-15.png-96.3kB](http://static.zybuluo.com/yaowen369/nm2iquifg6f4nuvmc0xk0zlq/%E5%AF%B9VP3%E4%B8%AD%E7%9A%84%E5%AD%97%E7%9A%84%E5%BA%94%E7%94%A8%E4%BC%9A%E5%BC%95%E8%B5%B7%E4%B8%8D%E5%91%BD%E4%B8%AD-15.png)

图15：对VP3中的字的应用会引起不命中


如上图所示，CPU 引用了 VP3 中的一个字， VP3 并未缓存在主存中。系统从内存中读取 PTE3, 会判断出 VP3 未被缓存，这会触发了一个**缺页异常**。缺页异常会调用kernel的缺页异常处理程序，该程序会选择一个牺牲页。如下图所示，在本demo中牺牲页选择了存放在 PP3 中的 VP4。

![VP4被牺牲了-16.png-92.5kB](http://static.zybuluo.com/yaowen369/jxkz8mi004r7ydyhbvcqw8n3/VP4%E8%A2%AB%E7%89%BA%E7%89%B2%E4%BA%86-16.png)
图16：VP4被牺牲了

此时如果 VP4 的内容被修改了，kernel会将它复制回磁盘。接下来，kernel从磁盘赋值 VP3 到内存中的 PP3并更新 PTE3。随后返回用户进程。当异常处理程序返回时，它会重启执行导致缺页的指令，而重新执行这条指令时，因为 VP3 已经在主存中了，此时就是页命中了。

![VP3被缓存到PP3-17.png-98.5kB](http://static.zybuluo.com/yaowen369/le12vevc07iit31xll0x7bua/VP3%E8%A2%AB%E7%BC%93%E5%AD%98%E5%88%B0PP3-17.png)

图17：VP3被缓存到PP3

根据虚拟内存习惯性的叫法，我们在磁盘和内存之间传送页的活动叫做**交换(swapping)**或者**页面调度(paging)**。这种交换活动，只有当不命中发生时才会发生，(也就说，系统并不会将磁盘内容预存到内存中)。这种策略被称之为**按需页面调度(demand paging)**。


> 我们刚才说，缺页错误是一种异常，但是实际上，在计算机系统中，被0除，读写文件，还有上篇文章中我们所说道的中断(interrupt)，甚至包括我们代码中写的`try catch`都是一种异常。 比如被0处是intel 的CPU规定的的第0号故障(fault)类型的异常。而读写文件，分别是linux系统规定的第0号和第1号陷阱(trap)类型的异常。，多任务的上下文切换，进程的创建回收等，等与系统中这种异常流的处理密切相关。当然，这是另外一个话题了。我们在这里不做累述。

## 虚拟内存作为内存管理和内存保护的工具

**理所当然的，每个进程都有一个独立的页表，因而也就是一个独立的虚拟地址空间**

我们在上面就提到过，比如基本上每个程序都要调用的 `stdio`这个库，不可能为每个进程都添加一个库，实际上内存中只有一份`stdio`库的内容，供每个使用该库的进程共享。

![共享页面-18.jpg-37.4kB](http://static.zybuluo.com/yaowen369/rteqhxa79gkmaan125nulnsf/%E5%85%B1%E4%BA%AB%E9%A1%B5%E9%9D%A2-18.jpg)

图18：共享页面

如上图所示: 第一个进程的的页表将 VP2 映射到 某个物理页面。而第二个进程同样将它的 VP2 映射到 该物理页面。所以该物理页面都被两个进程共享了。

> 此时，大家再看一下"图:12 进程地址空间",就会发现在内存的地址空间当中，"共享库的内存映射区域"对于每个进程都是相同的。所以说**虚拟内存简化了共享机制**

大家知道，C语言中存在指针，指针进行裸内存操作。因为有了虚拟内存，所以我们的裸内存操作也不会访问到其他进程的区域，但是哪怕是对于自己的地址空间，很多内存区域是不可能访问的，这不仅包括kernel的区域，也包括自己的只读代码段。那么虚拟内存就提供了这样的一种内存保护工具。

**地址翻译机制**可以使用一种自然的方式来提供内存的访问控制。PTE 上添加一些额外的控制位来控制对某个虚拟页面内容的访问。每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE ，

![虚拟内存提供内存保护-19.png-30.4kB](http://static.zybuluo.com/yaowen369/vzpgscdlyrsjxatdr7sihqle/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E6%8F%90%E4%BE%9B%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4-19.png)

图19：虚拟内存提供内存保护


在上图中，每个 PTE 额外添加了三个控制位， SUP 位表示进程是否必须运行内核模式下才能访问该页，WRITE 位控制页面的写访问权限， EXRC 位控制页面的执行。如果有指令违反了这些控制条件，那么 CPU 会触发一个故障，并将控制传递给内核中的异常处理程序。该种异常一般称为**段错误(segmentation fault)**。


[TODO](http://www.yaoxiaowen.com/)还有两个问题，没做，
1.页和段，段是什么
2，swap交互区是什么
3,貌似不叫做 内存影射、我靠